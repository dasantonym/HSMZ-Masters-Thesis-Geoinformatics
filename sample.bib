@online{pushingInteroperabilityForward,
  title = {Interop 2023: Pushing interoperability forward},
  author = {Davis, J. and Nguyen, T. and Simmons, J.},
  date = {2023-02-01},
  url = {https://webkit.org/blog/13706/interop-2023/},
  urldate = {2023-04-03},
  langid = {english},
  organisation = {WebKit},
}

% Sonification

@article{surveyOfPresence,
  title = {A Survey of Presence and Related Concepts},
  journaltitle = {{ACM} Computing Surveys},
  volume = {50},
  issue = {6},
  pages = {1-39},
  number = {96},
  author = {Skarbez, Rick and Brooks Jr., Frederick P. and Whitton, Mary C.},
  date = {2017-11-14},
  doi = {10.1145/3134301}
}

@thesis{movementQualities,
  title = {Computational models of expressive gesture in multimedia systems},
  author = {Gualtiero Volpe},
  date = {2003-04-22},
  library = {EURASIP Library of Ph.D. Theses},
  url = {https://theses.eurasip.org/theses/157/computational-models-of-expressive-gesture-in/download/},
  urldate = {2023-04-04},
}

@inproceedings{chromiumCustomHrtf,
  abstract = {This paper presents an application that demonstrates object-based 3D audio rendering in the web browser using the Web Audio API. The application loads audio files containing object-based meta-data and provides head-tracked dynamic binaural rendering of the content to create an immersive 3D audio experience for headphone listeners. The user can interact with the rendering by muting individual audio objects and switching between the binaural rendering mode and conventional stereo rendering. This application demonstrates the future of broadcast sound experiences over the web, where immersive content is rendered on the client and can be adapted to listener context, as page layout is adapted to device context today with responsive design.},
  address = {Paris, France},
  author = {Pike, Chris and Taylour, Peter and Melchior, Frank},
  booktitle = {Proceedings of the International Web Audio Conference},
  editor = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
  month = {January},
  pages = {},
  publisher = {IRCAM},
  series = {WAC '15},
  title = {Delivering Object-Based 3D Audio Using The Web Audio API And The Audio Definition Model},
  year = {2015},
  ISSN = {2663-5844}
}

@inproceedings{customHrtfAudioNode,
  abstract = {The Web Audio API is a powerful new platform for audio rendering within the browser and it provides a great opportunity for large deployment of audio applications. This paper explores the possibilities and limitations of the API for 3D sound spatialization based on binaural synthesis over headphones. The paper examines different processing structures and presents a new web-based server which allows the user to load individualized Head-Related Transfer Functions from a remote database.},
  address = {Paris, France},
  author = {Carpentier, Thibaut},
  booktitle = {Proceedings of the International Web Audio Conference},
  editor = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
  month = {January},
  pages = {},
  publisher = {IRCAM},
  series = {WAC '15},
  title = {Binaural synthesis with the Web Audio API},
  year = {2015},
  ISSN = {2663-5844}
}


% Concepts

@online{minskyTelepresence,
  title = {TELEPRESENCE},
  author = {Marvin Minsky},
  date = {1980-06-01},
  url = {https://web.media.mit.edu/~minsky/papers/Telepresence.html},
  urldate = {2024-01-15},
}

@incollection{vrHistoryGigante,
title = {1 - Virtual Reality: Definitions, History and Applications},
editor = {R.A. Earnshaw and M.A. Gigante and H. Jones},
booktitle = {Virtual Reality Systems},
publisher = {Academic Press},
address = {Boston},
pages = {3-14},
year = {1993},
isbn = {978-0-12-227748-1},
doi = {https://doi.org/10.1016/B978-0-12-227748-1.50009-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780122277481500093},
author = {Michael A. Gigante},
abstract = {Publisher Summary
Virtual reality (VR) has received an enormous amount of publicity over the past few years. Along with this publicity has arisen a great deal of conflicting terminology, some unrealistic expectations, and a great deal of uninformed commentary. This chapter discusses that VR is an interactive, participatory environment that could sustain many remote users sharing a virtual place. VR is characterized by the illusion of participation in a synthetic environment than external observation of such an environment. It relies on three-dimensional, stereoscopic, head-tracked displays, hand/body tracking, and binaural sound. VR is an immersive, multisensory experience. It is also referred to as virtual environments, virtual worlds, or microworlds. It has the potential to provide additional power to its users through increased perceptual fidelity. It can also improve the performance of users by lowering the cognitive load in the completion of a task. VR can improve the quality of life for workers in hazardous or uncomfortable environments and may eventually have impact on the whole society.}
}

@misc{
Heilig_1962,
title={SENSORAMA SIMULATOR},
author={Heilig, Morton L.},
year={1962},
month={Aug}
} 

@online{kinectDiscontinued,
  title = {Microsoft’s Azure Kinect Developer Kit Technology Transfers to Partner Ecosystem},
  author = {Swati Mehta},
  date = {2023-08-17},
  url = {https://techcommunity.microsoft.com/t5/mixed-reality-blog/microsoft-s-azure-kinect-developer-kit-technology-transfers-to/ba-p/3899122},
  urldate = {2024-01-15},
}

@article{ifMotionSounds,
title = {If motion sounds: Movement sonification based on inertial sensor data},
journal = {Procedia Engineering},
volume = {34},
pages = {556-561},
year = {2012},
note = {ENGINEERING OF SPORT CONFERENCE 2012},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2012.04.095},
url = {https://www.sciencedirect.com/science/article/pii/S1877705812017080},
author = {Heike Brock and Gerd Schmitz and Jan Baumann and Alfred O. Effenberg},
keywords = {Movement sonification, inertial sensor, data representation, motor learning, acoustic feedback},
abstract = {Within last years, movement sonification turned out to be an appropriate support for motor perception and motor control that can display physical motion in a very rich and direct way. But how should movement sonification be configured to support motor learning? The appropriate selection of movement parameters and their transformation into characteristic motion features is essential for an auditory display to become effective. In this paper, we introduce a real-time sonification framework for all common MIDI environments based on acceleration and orientation data from inertial sensors. Fundamental processing steps to transform motion information into meaningful sound will be discussed. The proposed framework of inertial motion capturing, kinematic parameter selection and possible kinematic acoustic mapping provides a basis for mobile real-time movement sonification which is a prospective powerful training tool for rehabilitation and sports and offers a broad variety of application possibilities.}
}

@inproceedings{sonificationPreHistory,
author = {Worrall, David},
year = {2018},
month = {06},
pages = {177-182},
title = {Sonification: A Prehistory},
doi = {10.21785/icad2018.019}
}

@book{sonificationHandbook,
  abstract     = {This book is a comprehensive introductory presentation of the key research areas in the interdisciplinary fields of sonification and auditory display. Chapters are written by leading experts, providing a wide-ranging coverage of the central issues, and can be read from start to finish, or dipped into as required (like a smorgasbord menu).
Sonification conveys information by using non-speech sounds. To listen to data as sound and noise can be a surprising new experience with diverse applications ranging from novel interfaces for visually impaired people to data analysis problems in many scientific fields.
This book gives a solid introduction to the field of auditory display, the techniques for sonification, suitable technologies for developing sonification algorithms, and the most promising application areas. The book is accompanied by an online repository of sound examples.},
  editor       = {Hermann, Thomas and Hunt, Andy and Neuhoff, John G.},
  isbn         = {978-3-8325-2819-5},
  keywords     = {User Interfaces, Sound Computing, Human Computer Interaction, Sonification, Auditory Display},
  pages        = {586},
  publisher    = {Logos Publishing House},
  title        = {{The Sonification Handbook}},
  url          = {https://nbn-resolving.org/urn:nbn:de:0070-pub-24423492, https://pub.uni-bielefeld.de/record/2442349},
  year         = {2011},
}

@online{webRtcGlobalIPSolutions,
  title = {Are the WebRTC components from Google’s acquisition of Global IP Solutions?},
  author = {Google},
  url = {https://web.archive.org/web/20110607005550/https://webrtc.org/faq/#TOC-Are-the-WebRTC-components-from-Goog},
  urldate = {2024-01-29}
}

@online{googleGlobalIpAcquisition,
  title = {Google makes \$68.2 million cash offer for Global IP Solutions},
  author = {{TechCrunch}},
  date = {2010-05-18},
  url = {https://techcrunch.com/2010/05/18/google-makes-68-2-million-cash-offer-for-global-ip-solutions/},
  urldate = {2024-01-29}
}

@online{webRtcArchitectures,
  title = {{WebRTC} Architecture Basics: {P2P}, {SFU}, {MCU}, and Hybrid Approaches},
  author = {Mukund Iyengar},
  url = {https://medium.com/securemeeting/webrtc-architecture-basics-p2p-sfu-mcu-and-hybrid-approaches-6e7d77a46a66},
  date = {2021-03-10},
  urldate = {2024-01-29},
}

@online{containerisationDefinition,
  title = {What is containerization?},
  author = {IBM},
  url = {https://www.ibm.com/topics/containerization},
  urldate = {2024-01-15},
}

@online{dockerRelease,
  title = {It's Here: Docker 1.0},
  author = {Julien Barbier},
  date = {2014-06-09},
  url = {https://web.archive.org/web/20220518024454/https://www.docker.com/blog/its-here-docker-1-0/},
  urldate = {2024-01-15},
}

@online{kubernetesHistory,
  title = {The History of {Kubernetes} \& the Community Behind It},
  author = {Brendan Burns},
  date = {2018-07-20},
  url = {https://kubernetes.io/blog/2018/07/20/the-history-of-kubernetes-the-community-behind-it/},
  urldate = {2024-01-15},
}

@online{javascriptHistory,
  title = {JavaScript History},
  author = {W3Schools},
  url = {https://www.w3schools.com/js/js_history.asp},
  urldate = {2024-01-15},
}

@online{javascriptRelease,
  title = {Netscape and {Sun} announce {JavaScript}},
  author = {Netscape},
  date = {1995-12-04},
  url = {https://web.archive.org/web/20070916144913/https://wp.netscape.com/newsref/pr/newsrelease67.html},
  urldate = {2024-01-15},
}

@online{typescriptRelease,
  title = {Microsoft Augments {Javascript} for Large-scale Development},
  author = {Joab Jackson},
  date = {2012-10-01},
  url = {https://web.archive.org/web/20131217223751/http://www.cio.com/article/717679/Microsoft_Augments_Javascript_for_Large_scale_Development},
  urldate = {2024-01-15},
}

@online{pythonHistory,
  title = {History of the software},
  author = {{Python Software Foundation}},
  url = {https://docs.python.org/3/license.html},
  urldate = {2024-01-15},
}


@online{pythonTyping,
  title = {Why is {Python} a dynamic language and also a strongly typed language?},
  author = {Guido van Rossum},
  date = {2008-08-11},
  url = {https://wiki.python.org/moin/Why%20is%20Python%20a%20dynamic%20language%20and%20also%20a%20strongly%20typed%20language},
  urldate = {2024-01-15},
}

@online{embeddedComputingDefinition,
  title = {Embedded Systems Glossary},
  author = {Michael Barr},
  date = {2015-10-08},
  url = {https://barrgroup.com/embedded-systems/glossary},
  urldate = {2024-01-20},
}

@online{arduinoHistory,
  title = {The Untold History of Arduino},
  author = {Hernando Barragán},
  date = {2022-06-16},
  url = {https://arduinohistory.github.io/},
  urldate = {2024-01-20},
}

@online{openContainerInitiative,
  title = {About the {Open Container Initiative}},
  author = {{Linux Foundation}},
  url = {https://opencontainers.org/about/overview/},
  urldate = {2024-01-15},
}

@online{cloudNativeComputingFoundation,
  title = {New {Cloud Native Computing Foundation} to drive alignment among container technologies},
  author = {{Linux Foundation}},
  date = {2015-07-21},
  url = {https://www.cncf.io/announcements/2015/06/21/new-cloud-native-computing-foundation-to-drive-alignment-among-container-technologies/},
  urldate = {2024-01-15},
}

@online{orchestrationDefinition,
  title = {What is container orchestration?},
  author = {IBM},
  url = {https://www.ibm.com/topics/container-orchestration},
  urldate = {2024-01-15},
}

@online{progressiveWebApplications,
  title = {Progressive Web Apps: Escaping Tabs Without Losing Our Soul},
  author = {Alex Russell and Frances Berriman},
  date = {2015-10-08},
  url = {https://medium.com/@slightlylate/progressive-apps-escaping-tabs-without-losing-our-soul-3b93a8561955},
  urldate = {2024-01-11},
}

@online{innerBrowsing,
  title = {Inner-Browsing: Extending Web Browsing the Navigation Paradigm},
  author = {Marcio Galli and Roger Soares and Ian Oeschger},
  date = {2003-05-16},
  url = {https://web.archive.org/web/20030810102320/http://devedge.netscape.com/viewsource/2003/inner-browsing/},
  urldate = {2024-01-11},
}

@online{ajaxNewApproach,
  title = {Ajax: A New Approach to Web Applications},
  author = {Jesse James Garrett},
  date = {2005-02-18},
  url = {https://web.archive.org/web/20150910072359/http://adaptivepath.org/ideas/ajax-new-approach-web-applications/},
  urldate = {2024-01-11},
}

@online{vueProgressiveFramework,
  title = {Introduction: The Progressive Framework},
  author = {Evan You},
  date = {2021-09-29},
  url = {https://vuejs.org/guide/introduction.html#the-progressive-framework},
  urldate = {2024-01-14},
}

@online{expressJsStrongLoop,
  title = {{TJ Holowaychuk} Passes Sponsorship of {Express} to {StrongLoop}},
  author = {Al Tsang},
  date = {2014-07-29},
  url = {https://web.archive.org/web/20161011091052/https://strongloop.com/strongblog/tj-holowaychuk-sponsorship-of-express/},
  urldate = {2024-01-14}
}

@online{expressJsStrongLoopIbm,
  title = {{IBM} snaps up {StrongLoop} to add {Node.js} smarts to {BlueMix}},
  author = {Serdar Yegulalp},
  date = {2015-09-10},
  url = {https://web.archive.org/web/20221013083101/https://www.infoworld.com/article/2982876/ibm-snaps-up-strongloop-to-add-nodejs-smarts-to-bluemix.html},
  urldate = {2024-01-14}
}

@online{expressJsNodeFoundation,
  title = {{Node.js} Foundation to shepherd {Express} Web framework},
  author = {Paul Krill},
  date = {2016-02-10},
  url = {https://www.infoworld.com/article/3031686/nodejs-foundation-to-shepherd-express-web-framework.html},
  urldate = {2024-01-14}
}

@online{feathersFrameworkHistory,
  title = {Why we built the best web framework you’ve probably never heard of (until now).},
  author = {Eric Kryski},
  date = {2016-04-06},
  url = {https://blog.feathersjs.com/why-we-built-the-best-web-framework-you-ve-probably-never-heard-of-until-now-176afc5c6aac},
  urldate = {2024-01-17},
}

@online{meteorSaleTinyCapital,
  title = {Tiny acquires {Meteor}},
  author = {Frederic Lardinois},
  date = {2019-10-02},
  url = {https://techcrunch.com/2019/10/02/tiny-acquires-meteor/},
  urldate = {2024-01-17},
}

@online{meteorDiscussionYCombinator,
  title = {HackerNews: Tiny Acquires {Meteor}},
  author = {doppp and {forum users}},
  date = {2019-10-02},
  url = {https://news.ycombinator.com/item?id=21137653},
  urldate = {2024-01-17},
}

@online{livekitAbout,
  title = {LiveKit: About},
  author = {LiveKit},
  url = {https://livekit.io/about},
  urldate = {2024-01-19},
}

@INPROCEEDINGS{poseEstimationPaper,
  author={Ye, Mao and Xianwang Wang and Yang, Ruigang and Liu Ren and Pollefeys, Marc},
  booktitle={2011 International Conference on Computer Vision}, 
  title={Accurate {3D} pose estimation from a single depth image}, 
  year={2011},
  volume={},
  number={},
  pages={731-738},
  doi={10.1109/ICCV.2011.6126310}}
}

@misc{kendall2016posenet,
      title={PoseNet: A Convolutional Network for Real-Time 6-DOF Camera Relocalization}, 
      author={Alex Kendall and Matthew Grimes and Roberto Cipolla},
      year={2016},
      eprint={1505.07427},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{bazarevsky2020blazepose,
      title={BlazePose: On-device Real-time Body Pose tracking}, 
      author={Valentin Bazarevsky and Ivan Grishchenko and Karthik Raveendran and Tyler Zhu and Fan Zhang and Matthias Grundmann},
      year={2020},
      eprint={2006.10204},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@book{patternOrientedSoftwareArchitecture,
author = {Buschmann, Frank and Henney, Kevlin and Schmidt, Douglas},
title = {Pattern-Oriented Software Architecture: A Pattern Language for Distributed Computing},
year = {2007},
isbn = {0470059028},
publisher = {John Wiley \& Sons, Inc.},
address = {Hoboken, NJ, USA},
abstract = {Providing a guide to the best practices in key areas of distributed computing, this book describes a single pattern language that links many patterns relevant to distributed computing.}
}

@ARTICLE{mcCabeComplexity,
  author={McCabe, T.J.},
  journal={IEEE Transactions on Software Engineering}, 
  title={A Complexity Measure}, 
  year={1976},
  volume={SE-2},
  number={4},
  pages={308-320},
  keywords={Software testing;System testing;Graph theory;Fluid flow measurement;Software measurement;Linear programming;Software engineering;Software systems;Software maintenance;National security;Basis;complexity measure;control flow;decomposition;graph theory;independence;linear;modularization;programming;reduction;software;testing},
  doi={10.1109/TSE.1976.233837}
}

@TECHREPORT{sonarSourceCognitiveComplexity,
  author={G. Ann Campbell},
  title={Cognitive Complexity: a new way of measuring understandability}, 
  year={2023},
  month={August},
  url={https://www.sonarsource.com/resources/cognitive-complexity/},
  urldate={2024-02-04}
}

@misc{testingCyclomaticComplexity,
  author = {D Wallace and A Watson and T Mccabe},
  title = {Structured Testing: A Testing Methodology Using the Cyclomatic Complexity Metric},
  year = {1996},
  month = {1996-08-01},
  publisher = {Special Publication (NIST SP), National Institute of Standards and Technology, Gaithersburg, MD},
  language = {en},
}

@inproceedings{softwareMetricsReliability,
  title={SOFTWARE METRICS AND RELIABILITY},
  author={Linda H. Rosenberg and Theodore Hammer and John G. Shaw},
  year={1998},
  url={https://api.semanticscholar.org/CorpusID:59798472}
}

@article{open3DZhou2018,
   author  = {Qian-Yi Zhou and Jaesik Park and Vladlen Koltun},
   title   = {{Open3D}: {A} Modern Library for {3D} Data Processing},
   journal = {arXiv:1801.09847},
   year    = {2018},
}

@online{abzgPar3,
  author = {{Bundesamt für Justiz}},
  title = {Arbeitszeitgesetz (ArbZG) § 3 Arbeitszeit der Arbeitnehmer},
  url = {https://www.gesetze-im-internet.de/arbzg/__3.html},
  urldate = {2024-02-04}
}

@INPROCEEDINGS{audioLatency,
  author={Hopkins, Torin and Weng, Suibi Che-Chuan and Vanukuru, Rishi and Wenzel, Emma and Banic, Amy and Do, Ellen Yi-Luen},
  booktitle={2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)}, 
  title={How Late is Too Late? Effects of Network Latency on Audio-Visual Perception During AR Remote Musical Collaboration}, 
  year={2022},
  volume={},
  number={},
  pages={686-687},
  keywords={Three-dimensional displays;Conferences;Avatars;Collaboration;Music;User interfaces;Real-time systems;Human-centered computing—Interaction paradigms—Mixed / augmented reality;Human-centered computing—Interaction paradigms—Collaborative Interaction;Applied computing—Sound and music computing},
  doi={10.1109/VRW55335.2022.00194}
}

