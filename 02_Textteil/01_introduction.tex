\chapter{Introduction}
\label{ch:introduction}

\section{Background}
\label{sec:background}

Remote collaboration has become increasingly prevalent in various professional environments through broader digitalisation efforts and significantly accelerated during the COVID-19 pandemic.
As a result, teleconferencing and telepresence platforms that were initially used primarily for international business relations are now much more common in many work environments.
These technologies allow people to work together remotely in real time, usually focusing on streaming video and audio, document sharing and collaborative whiteboarding.
While this covers most use cases in desk-based workplaces, it lacks the immersive qualities required for practices such as contemporary dance, where people relate to physical presence and shared space.
This became apparent in March 2020, when dancers could no longer rehearse and work together due to the lockdown.
Despite this, there were attempts at using videoconferencing to stream and record collaborative rehearsals or dance classes.
Still, these were confined to a screen-centric interface and limited to audio and video.

While commercial conferencing tools dominate in popularity among conferencing applications~\parencite{mostPopularConferencingPlatforms}, there are several free and open-source alternatives.
However, these all focus on the most basic form of screen-based conferencing.
Various domain-specific solutions for specialised applications, mainly in telemedicine, industry and the military, support more immersive remote collaboration.
Still, these are task-specific and difficult to afford for smaller creative or artistic project setups.

Support for web standards is driven by key industry players~\parencite{pushingInteroperabilityForward}, making a wide range of basic functionality accessible in web browsers, as well as access to display and sensor technology and cross-platform deployment on desktop and mobile devices.
This development now provides an increased potential for smaller and more task-specific applications to be built and deployed relatively quickly.
It opens up new possibilities for niche cases of remote collaboration, such as dance practice, where the collaborative agency could be extended from a composite of video streams to the creation of shared virtual environments that facilitate a more personal form of mediating a sense of shared presence.

The standard for \ac{RTC} in Browsers or \ac{WebRTC}~\parencite{webRtcSpec} was first proposed by Google in 2011 and became an official \ac{W3C} standard in 2021~\parencite{webRtcOfficialWebStandard}.
It has become the basis for numerous applications, such as some of the conferencing tools mentioned above, media streaming servers, or real-time frameworks.
In its most basic form, \ac{WebRTC} establishes peer-to-peer connections between devices, allowing low-latency exchange of media streams and arbitrary messages over data channels.
However, it can accommodate other more complex and versatile scenarios.

\section{Proposal}
\label{sec:proposal}

The proposed study examines the feasibility of creating a customised telepresence experience that explicitly covers a specific task not provided by common platforms or products.
A potential target audience for such an application would be tiny and hardly warrants a commercial strategy of external product development, marketing and support.
Extensive software development budgets are also rare in funding schemes supporting smaller cultural production endeavours, and it is relatively common for practitioners themselves to dabble in experimental development or to have a creative coder on the team.
To keep the budgetary requirements for such an implementation at a minimum, relying on open standards and non-proprietary components is imperative.
While the implementation has to fulfil a particular task, some level of abstraction, modular composition and separation of concerns are important design factors that allow for establishing a technological base that can be reused in multiple contexts with less work in subsequent deployment instances.

To support a broad range of scenarios, the application core should support the real-time streaming of any type of sensor data in addition to the usual video and audio streams.
This would allow augmenting the telepresence environment with spatial data, sensor readings or generative data sources.
The data could then be streamed as is but visualised, sonified, or otherwise analysed and processed on the receiving devices as required by the implemented use case.
In this reference implementation, movement sonification is implemented as an alternative to the visually-centred conferencing paradigms.
As movement in front of a screen or with headsets can be somewhat limiting, the idea is to use spatial audio for movement sonification and voice communication to provide a sense of positional orientation in relation to the virtual presence in the space.
Focused on a scenario of two participants moving at remote locations but in virtually overlayed spatial dimensions, this setup could enable exploration of moving together by attempting to achieve some form of acoustic harmony or rhythm to supplant an actual shared physical presence.
This implementation targets only a small audience in that it requires practice and a deep engagement with the sonification method, explained in detail in \autoref{sec:sonification-method-and-sound-spatialisation}, as it would be specifically built to express a specific style of movement that would not be intuitive for every potential user alike.
It should also be used by dancers with a shared experience of moving together so that verbal communication can support navigating a shared movement vocabulary and connecting to the memory of shared physical practice.
Creative design processes and user experience are deemed outside the scope of this study, as the focus lies on examining the general feasibility and affordability of using open standards and free software to enable the creation of a task-specific real-time application, exemplified by the proposed reference implementation and examined in its general abstract functionality instead of usability or user experience.

\section{Structural outline}
\label{sec:outline}

The study starts from a survey of \emph{conceptual foundations} presenting existing paradigms and technologies to support the development of web-based real-time applications (\autoref{ch:conceptualfoundations}), establishes a \emph{research methodology} (\autoref{ch:methodology}) and presents an \emph{application concept} (\autoref{ch:concept}) as well as a description of the resulting {reference implementation} (\autoref{ch:implementation}).
The reference implementation is the basis for a \emph{discussion} of the reference implementation's general performance, code quality, the amount of time invested in its creation and a critical reflection on the development process (\autoref{ch:discussion}).
The study \emph{concludes} with a general recommendation on the feasibility of creating such a \textquote{single-use} application for a specific task and an \emph{outlook} for future implications and possibilities resulting from this research (\autoref{ch:conclusion-and-outlook}).
