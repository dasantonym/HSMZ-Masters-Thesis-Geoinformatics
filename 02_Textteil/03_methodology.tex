\chapter{Research methodology}
\label{ch:methodology}

This feasibility study was based on two essential parts.
The first was a reference implementation, providing insights into the work necessary for a basic functional implementation.
Based on this implementation, the application\textquotesingle s abstract performance was measured, an evaluation of the time spent on development was made, a qualitative review of the resulting codebase, and a critical reflection on the work process.

\section{Reference implementation}
\label{sec:reference-implementation}

To produce a valid test subject for the proposal, the reference implementation was created according to a prior selection of tools and methods deemed appropriate for the project.
The choices were made from the concepts and tools presented in \autoref{ch:conceptualfoundations}.

First, possible candidates were identified through internet research, and then at least three candidates were selected using the number of \textquote{Stars} received on GitHub as an indicator of popularity.
In some cases, other data sources had to be used where the technology predates GitHub (e.g.\ databases or programming languages), and its popularity should be judged by other means.
Developer surveys are being conducted by the popular technology forum Stack Overflow with over 90.000 participants for 2023~\parencite{stackOverflowPoll} and the \textquote{State Of JS} survey with over 20.000 participants that is more focused on web development~\parencite{stateOfJSSurvey}.
Additionally, GitHub publishes a yearly statistic on its public repositories, which helps identify technological trends and popularity among millions of open-source repositories~\parencite{stateOfTheOctoverse23}.
These sources provided additional input on popularity among a specific professional field and a general overview of technologies actively used.
The decision on choosing a candidate was made not by popularity alone, but with a stronger weight on a good fit to the project\textquotesingle s specific requirements and needs.
If a less popular framework did fit the specific development style, it would still be preferred to the popular status quo.
Another case might be a more recent project that has yet to collect as high of a rating on GitHub but presents a promising new approach or feature set.

The application development worked from the most basic boilerplate code towards finding the appropriate structure for the specific use case.
Well-known and easily defined components were built first.
The particular functionality of the reference implementation was then built on top in constant cycles of adding functionality, reviewing the codebase and refactoring towards abstraction and separation of basics from specifics.
As only a rough architectural model for the project was defined beforehand, tests and documentation were written later in the process, as the parts stabilised independently and in their relationship with each other.
This method does not strictly adhere to standard development procedures.
Still, it borrows loosely from agile development (sprints, reviews, adjustments) and simple forms of the ideas put forward in the book \textquote{Pattern-Oriented Software Architecture}, such as application partitioning through layering, separation, and standardised messaging~\parencite{patternOrientedSoftwareArchitecture}.
A more systemic approach for the development process, like application modelling using \ac{UML} and test-driven development, might be desirable for teams, but the various and disparate \textquote{moving parts} in conjunction with heavy reliance on browser-only \ac{API}s complicate the creation of a well-simulated testing environment using either real or mock-data, especially for a single developer.

The application was implemented in its entirety, documented, packaged and deployed.
Appropriate test coverage was provided for the core functionality, and the overall time spent was logged in timesheets and categorised by the general work areas.
The application\textquotesingle s server components were deployed early on to university hardware and made available over the internet.
The client application was then run and tested on exemplary computer systems in and outside the university network.

\section{Analysis and evaluation}
\label{sec:analysis-evaluation}

A statistical analysis of the timesheets provided insight into the \emph{workload} time spent on various aspects of the software.
It differentiated between languages and application components to provide insights into the feasibility of setting up such a system from scratch with a single developer and the potential cost of just reworking the parts deemed transient and related to the specific use case.

The application\textquotesingle s \emph{performance} was tested regarding the load put on the \ac{CPU} (server and client) and the network throughput and latency.
It was verified that all message processing worked as expected through unit testing and simple manual testing tasks performed on the application.
A practical test that analyses the actual user experience and uses performers and real dance interaction was deemed beyond the scope of this study.

The \emph{code quality} was assessed based on volume (source code files and lines of code without comments) and cognitive complexity, ~\parencite[see][]{sonarSourceCognitiveComplexity}, which is an updated version of the older concept of cyclomatic complexity, which counts the number of linearly independent paths throughout a piece of code~\parencite[see][]{mcCabeComplexity}.
It was published by the Swiss company SonarSource\footnote{\url{https://www.sonarsource.com/}} and \textquote{has been formulated to address modern language structures, and to produce values that are meaningful at the class and application levels.}~\parencite[4]{sonarSourceCognitiveComplexity}
It accounts for modern control structures and aims to facilitate legibility by rewarding a code style that benefits general understandability~\parencite[4]{sonarSourceCognitiveComplexity}.
Both metrics should be kept low for each source code file, as code with many lines makes it harder to read, and high complexity is more challenging to follow and understand.
The code volume is difficult to reduce to a static maximum, but \textquote{the [\ac{SATC}] has found the most effective evaluation is a combination of size and complexity}~\parencite[6]{softwareMetricsReliability}, so a self-imposed threshold should be set, even if exceptions are made later.
For \ac{OOP}, limiting a file to a single class is often advised.
Still, depending on the language used, the file can also contain multiple functions that are better grouped instead of scattered across various files.
A general rule of thumb proven to be a good measurement from experience is that a single file should be at most 160-200 lines of code (without comments) to skim it and get a general overview quickly.
There are exceptions to these rules where a specific function or class exceeds this threshold, but breaking it up would not make it easier to understand.
In those cases, there can be a discussion about changing the general application design to partition the functionality differently.
Alternatively, it can be decided to keep this code and improve documentation.
Reducing volume and complexity is especially important if the code should be passed on to others who want to maintain and modify it for further use.
Here, the general idea was that the transient (hackable) parts (e.g. \ac{UI}) should be kept as simple as possible, avoiding unnecessary complexity.
The more static and stable core components would then be where the complex code would be moved to (e.g.\ the core \ac{SDK}).

Additionally, a \emph{critical reflection} and analysis of the development process was created to weigh the expectations against the experiences while implementing the decisions made in planning the application.
It evaluated general reproducibility and feasibility and discussed the benefits and limitations of establishing a task-specific application from scratch using the proposed concept.
